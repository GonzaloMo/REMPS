{"Training": {"stop": {"timesteps_total": 100000000}, "local_dir": "./Logs/RLAgent_3/SimpleSatellite-setgoals-v0", "checkpoint_freq": 1000000, "checkpoint_at_end": true, "checkpoint_score_attr": "episode_reward_mean", "export_formats": ["h5"], "config": {"framework": "torch", "lambda": 0.95, "kl_coeff": 0.5, "clip_rewards": true, "clip_param": 0.1, "vf_clip_param": 10.0, "entropy_coeff": 0.01, "train_batch_size": 5000, "lr":  0.001, "rollout_fragment_length": 20, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "num_workers": 5, "num_envs_per_worker": 5, "batch_mode": "truncate_episodes", "observation_filter": "NoFilter", "num_gpus": 0, "model": {"dim": 42, "vf_share_layers": true}, "evaluation_interval": 100000, "evaluation_duration": 100, "evaluation_config": {"render_env": false}, "render_env": false, "env_config": {"env": "SimpleSatellite-setgoals-v0", "Reward_Module": "Configurations.RLAgent.Reward_functions.SimpleSatSetGoals", "Reward_Function": "Reward_v0", "Log_dir": "./Simulation/", "Env_setup": "./Configurations/RLAgent/Environment_Config/Env_4.yaml"}, "env": "SimpleSatellite-setgoals-v0"}, "restore": null, "name": "Env_4"}, "Agent": {"Algorithm": "PPO", "Agent_Config": ["./Configurations/RLAgent/Agent_Config/PPO_Config_search.yaml"]}, "Environment": {"Trianing_Envs": ["./Configurations/RLAgent/Environment_Config/Env_4.yaml"], "render_env": false, "env_config": {"env": "SimpleSatellite-setgoals-v0", "Reward_Module": "Configurations.RLAgent.Reward_functions.SimpleSatSetGoals", "Reward_Function": "Reward_v0", "Log_dir": "./Simulation/", "Env_setup": "./Configurations/RLAgent/Environment_Config/Env_4.yaml"}}, "save_dir": "/home/ksb21109/REMPS/Test/Logs/RLAgent_3/SimpleSatellite-setgoals-v0/Env_4/PPO_SimpleSatellite-setgoals-v0_f68c3_00000_0_lr=0.0001_2022-11-11_13-44-28", "last_checkpoint": "/home/ksb21109/REMPS/Test/Logs/RLAgent_3/SimpleSatellite-setgoals-v0/Env_4/PPO_SimpleSatellite-setgoals-v0_f68c3_00000_0_lr=0.0001_2022-11-11_13-44-28/checkpoint_020000/"}