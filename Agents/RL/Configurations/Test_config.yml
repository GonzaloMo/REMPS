Environment:

  # (List[str]) – List of environments to be trainned in sequence carrying the weights. [""./Configurations/Environment_Config/Env_1.yaml""]
  Env_setup: "./Configurations/Environment_Config/Env_1.yaml" 

  # (str) – The gym environment to use. This can also be a callable that returns a gym environment when called.
  env: "SimpleSatellite-setgoals-v0"

  # (str) – Module name of the Reward Function. Default set to "Reward_Function"
  Reward_Module: "Reward_functions.SimpleSat"

  # (str) – Reward function to be used. Default set to "Reward_1"
  Reward_Function: "Reward_v1"

  # (str) – Directory to save the results. Default set to "./Results"
  Log_dir: "./Results/Env_1"

Agent:
  # (str) – Name of the algorithm to be used. Default set to "PPO". ["PPO", "DQN", "DDPG", "TD3", "SAC"]
  Algorithm: "PPO"
  # (List[str]) – List of combinable agent Configuration files. Default ["./Configurations/Agent_Config/PPO_Config.yaml"]
  Agent_Config: ["./Configurations/Agent_Config/PPO_Config.yaml"]
